<h1 align="center">üçΩÔ∏è Proyecto Final Henry - StarSight üó∫Ô∏è</h1>

![Starsight](Imagenes/starsight.jpg)

## **üìã √çndice**

1. [Integrantes](#Integrantes)
2. [Introduccion a StarSight](#Introducci√≥n-a-StarSight)
3. [Contexto](#contexto)
4. [Desarrollo del proyecto](#Desarrollo-del-proyecto)
5. [Alcance del proyecto](#-alcance-del-proyecto)
6. [Objetivos](#-objetivos)
7. [KPI'S](#-kpis)
8. [Flujo de trabajo](#-flujo-de-trabajo)
9. [Diagrama ER](#diagrama-e-r)
10. [Metodologia](#-metodolog√≠a-del-trabajo)
11. [Conclusiones](#Conclusiones)


## **Integrantes**

- [Mar√≠a Jos√© Grecco](https://github.com/mpaezgrecco) - *Data Analist*
- [Esteban Parron](https://github.com/systemeap) - *Data Analist*
- [Santiago Mej√≠a](https://github.com/SantiagoMejiaGuerra) - *Data Analist*
- [Joaqu√≠n Rubiolo](https://github.com/joarubiolo) - *Data Scientist*
- [Luis Gonzalez](https://github.com/lucho28) - *Data Engineer*

## **Introducci√≥n a StarSight**

En el sector de la industria gastron√≥mica, las rese√±as de los clientes en l√≠nea juegan un papel crucial en la reputaci√≥n y el √©xito de los negocios. La retroalimentaci√≥n p√∫blica, visible en plataformas como *Yelp* y *Google Maps*, no solo influye en la percepci√≥n de los potenciales clientes, sino que tambi√©n ofrece una fuente rica de datos para optimizar la experiencia del usuario y los servicios ofrecidos.

<p align="center">
  <img src="https://blog.reviewpoint.com/hubfs/customer_review_tips.png" alt="Logo del Proyecto" width="500">
</p>

StarSight surge con el prop√≥sito de transformar estas opiniones en informaci√≥n valiosa para que los establecimientos puedan tomar decisiones informadas y orientadas a la mejora continua. Nos especializamos en la implementaci√≥n de modelos de aprendizaje autom√°tico (ML) adaptados a las necesidades espec√≠ficas de nuestros clientes en el mercado gastron√≥mico, extrayendo patrones clave y recomendaciones accionables que impulsan el crecimiento y la satisfacci√≥n del cliente en este sector.
Con nuestro enfoque personalizado y anal√≠tico, StarSight se posiciona como el aliado estrat√©gico de los negocios gastron√≥micos que buscan aprovechar los datos de rese√±as en l√≠nea para diferenciarse en el mercado y mejorar su rendimiento.

## **Contexto**

Nuestro cliente nos ha solicitado un an√°lisis enfocado en restaurantes en el estado de Florida, un mercado altamente competitivo donde las opiniones de los consumidores juegan un rol crucial. Este proyecto aprovechar√° las rese√±as en l√≠nea para ofrecer insights estrat√©gicos y recomendaciones pr√°cticas, ayudando a nuestros clientes a mejorar la experiencia del cliente y fortalecer su posici√≥n en el mercado.

## **üöÄ Desarrollo del proyecto**
![desarrollo](https://netlok.com/wp-content/uploads/egencia-business-travel-banner-solutions.jpg)

Comenzamos identificando las diferentes problem√°ticas que enfrenta la industria gastron√≥mica con servicio directo al consumidor final. Algunos puntos clave a tener en cuenta son:

- **An√°lisis de la percepci√≥n del cliente**: Interpretaci√≥n de las impresiones que adquiere el usuario sobre la calidad, servicio u otros aspectos del negocio.
- **Predicci√≥n de tendencias de mercado**: Necesidad de anticiparse a cambios y adaptarse r√°pidamente a las nuevas formas de consumo.
- **Selecci√≥n de ubicaciones estrat√©gicas**: Identificaci√≥n de los mejores lugares para abrir nuevos negocios o expandirse.
- **Personalizaci√≥n de la experiencia del usuario**: Fortalecer el v√≠nculo con potenciales clientes a trav√©s de la personalizaci√≥n.
- **Alta competencia y mercado saturado**: Dificultad para el desarrollo natural de los negocios debido a la saturaci√≥n del mercado.

Utilizamos diversas herramientas para abordar estas dificultades, considerando factores del mercado actual, y buscando oportunidades para fortalecer el negocio y evitar amenazas de la competencia.

<!-- Alcance section -->
## **üåê Alcance del proyecto**

**Extracci√≥n de Datos:** Recopilaci√≥n y utilizaci√≥n de datos provenientes de plataformas de rese√±as como Google Maps y Yelp.

**An√°lisis de Datos:** Implementaci√≥n de t√©cnicas avanzadas de An√°lisis de Datos y Aprendizaje Autom√°tico para examinar las rese√±as de los usuarios.
El an√°lisis permitir√° al sistema identificar tendencias y generar recomendaciones consistentes.

**Cobertura Geogr√°fica:** Enfoque espec√≠fico en los establecimientos gastron√≥micos ubicados en el estado de Florida en los Estados Unidos.

**Visualizaci√≥n y Sistema de Recomendaci√≥n:** Desarrollo de una interfaz de usuario intuitiva que permita a los clientes seleccionar sus criterios para la b√∫squeda de restaurantes.
Presentaci√≥n visual de los resultados de las recomendaciones.
<!-- objetivos section -->
## **üéØObjetivos**

1. Realizar un an√°lisis exhaustivo del mercado gastron√≥mico en el estado de Florida, aprovechando el valor de los datos para comprender el comportamiento de los consumidores y la competitividad del sector.

2. Buscar e identificar restaurantes de comida americana en el estado de Florida, utilizando t√©cnicas de an√°lisis de datos para obtener insights sobre su presencia y caracter√≠sticas en el mercado.

3. Evaluar oportunidades de crecimiento y expansi√≥n en el sector gastron√≥mico mediante el an√°lisis de distintos escenarios en el estado de Florida.

4. Desarrollar un modelo predictivo para optimizar la selecci√≥n de √°reas estrat√©gicas para la apertura de nuevos restaurantes.

### **üåü Objetivos Comunes**

1. **Extracci√≥n de datos desde la fuente:** Utilizar los datos proporcionadas de Yelp y Google Maps, as√≠ como la recolecci√≥n de datos propia y el scrapping para obtener variables demogr√°ficas.

2. **Disponibilizar datos en la nube:** Implementar un proceso de carga incremental con servicios de Amazon Web Servise (AWS) para permitir el acceso a los datos desde nuestra plataforma.

3. **Limpieza de Datos:** Corregir valores at√≠picos, gestionar datos faltantes y normalizar los datos para garantizar su integridad antes del an√°lisis.

4. **Automatizaci√≥n:** Automatizar en la medida de lo posible el proceso de extracci√≥n, transformaci√≥n y carga (ETL) para mejorar la eficiencia y reducir los riesgos de errores manuales.

5. **Documentaci√≥n:** Detallar exhaustivamente todo el proceso de ETL, incluyendo fuentes de datos, transformaciones realizadas y criterios de calidad aplicados, para facilitar la replicabilidad y el mantenimiento del proceso.

<p align="right">(<a href="#readme-top">volver arriba</a>)</p>

‚ÄÉ<!-- KPI section -->
## **üìä KPI¬¥s:**

1. **Aumentar el promedio de horas de operaci√≥n:** 
* **Descripci√≥n**: Mide el promedio de horas semanales que operan los restaurantes de comida americana en Florida.

* **Objetivo**: Aumentar este promedio a 40 horas semanales en un periodo de 2 a√±os.

$$
\mathrm{KPI} = \frac{\sum \text{Horas de operaci√≥n}}{\text{Total de restaurantes}}
$$
<br>

2. **Aumento estandar de 4 estrellas:** 
* **Descripci√≥n**:Calcula el promedio de estrellas o calificaci√≥n general recibida por los restaurantes de comida americana.
* **Objetivo**: Alcanzar un promedio de 4 estrellas en el transcurso de un a√±o.

$$
\mathrm{KPI} = \frac{\sum \text{Calificaci√≥n de estrellas}}{\text{Total de restaurantes}}
$$

<br>

3. **Incrementar el promedio de interacciones por estado:** 
* **Descripci√≥n**:Mide la cantidad promedio de interacciones (rese√±as, calificaciones, etc.) que reciben los restaurantes en cada estado, con enfoque en Florida.
* **Objetivo**: Incrementar este promedio en el estado de Florida para el pr√≥ximo a√±o.

$$
\mathrm{KPI} = \frac{\sum \text{Interacciones en florida}}{\text{Total de restaurantes}}
$$

<br>

<!-- flujo section -->
## **üîß Flujo de Trabajo**

### 1. ETL 

Nuestra base de datos principal proviene de **Yelp** y **Google Maps**.
A continuacion podras encontrar la fuente de datos principal para la realizacion del proyecto: 

- [Dataset de Google Maps](https://drive.google.com/drive/folders/1Wf7YkxA0aHI3GpoHc9Nh8_scf5BbD4DA)
- [Dataset de Yelp!](https://drive.google.com/drive/folders/1TI-SsMnZsNP6t930olEEWbBQdo_yuIZF)

Al recibir los datos en bruto, se lleva a cabo un trabajo manual y estandarizado de ETL utilizando Python y las librer√≠as pertinentes.Este proceso incluye la eliminaci√≥n de columnas irrelevantes, desanidamiento de columnas si es necesario, manejo de valores nulos y duplicados, normalizaci√≥n de tipos de datos y nombres de columnas seg√∫n un esquema estandarizado.
Posteriormente realizamos un **An√°lisis de Datos Exploratorio (EDA)** en el que identificamos las variables m√°s relevantes dentro de los comentarios publicados, utilizando librer√≠as como **Pandas** y **Numpy**.
El an√°lisis proporciona una visi√≥n general del dataset, el cual es limpiado y procesado para obtener m√©tricas b√°sicas. 

<p align="center">
  <img src="Imagenes/grafico.jpg" alt="Logo del Proyecto" width="500">
</p>

<p align="center">
  <img src="Imagenes/mapa_page-0001.jpg" alt="Logo del Proyecto" width="800">
</p>

Para poder guiarse en el proyecto, puede encontrar los ETL y EDA correspondientes en las carpetas de ./ETL_EDA_GOOGLE y ./ETL_EDA_YELP dentro de este repositorio, dentro de las cuales se encuentran los distintos elementos del dataset procesados y explorados para extraer la mayor cantidad de informacion posible. 

<p align="center">
  <img src="Imagenes/screenshot.png" alt="Logo del Proyecto" width="800">
</p>

### Pipeline

1. Carga de Archivos CSV en S3 (Fuente de Datos)

El proceso comienza con la carga de archivos CSV en un bucket de Amazon S3. Estos archivos pueden provenir de m√∫ltiples fuentes de datos, ya sea de procesos manuales o automatizados que recolectan y transfieren datos a S3. Al centralizar la carga en S3, se proporciona un repositorio accesible y seguro para almacenar datos sin procesar.

2. Detecci√≥n Autom√°tica de Nuevas Cargas

Se configura una notificaci√≥n de eventos en el bucket de S3 que desencadena una funci√≥n Lambda cada vez que se carga un nuevo archivo. Este evento de S3 puede ser programado para detectar √∫nicamente cargas completas, evitando la activaci√≥n prematura durante una carga en progreso.

3. Verificaci√≥n de Archivos por Nombre

La funci√≥n Lambda que se activa primero realiza una verificaci√≥n en la base de datos MySQL en Amazon RDS. Consulta una tabla espec√≠fica de registros de archivos para determinar si el archivo reci√©n cargado ya ha sido procesado. Este paso es crucial para evitar duplicados y garantizar la integridad de los datos.

Estrategia Escalable: Puedes escalar este proceso creando funciones Lambda espec√≠ficas para diferentes tablas de la base de datos. Esto permite que el sistema se adapte a un mayor n√∫mero de tipos de datos y formatos de archivo sin necesidad de redise√±ar todo el pipeline.

4. Invocaci√≥n de Funci√≥n Lambda para Procesamiento y Carga

Si la funci√≥n Lambda de verificaci√≥n determina que el archivo es nuevo, se activa una segunda funci√≥n Lambda encargada de procesar y cargar los datos. Esta funci√≥n accede al archivo en S3 y lo prepara para su inserci√≥n en la base de datos. Durante este proceso, se aplican ciertos controles para asegurar la integridad de los datos:

* Control de Duplicados: La funci√≥n est√° dise√±ada para evitar la inserci√≥n de datos repetidos en la base de datos. Si encuentra registros que ya existen, los ignora o actualiza solo ciertos campos, garantizando que la informaci√≥n almacenada sea precisa y est√© al d√≠a.
* Transformaciones de Datos: Si es necesario, los datos se pueden ajustar para que sean consistentes y est√©n listos para la carga.
* Validaciones B√°sicas: Se realizan comprobaciones r√°pidas para confirmar que los datos cumplen con las expectativas antes de cargarse.
De esta manera, la funci√≥n asegura que solo se agreguen datos nuevos o actualizados, sin sobrescribir informaci√≥n valiosa de manera innecesaria. Al final, los datos ingresan a la base de datos en un estado √≥ptimo, listos para ser utilizados en an√°lisis y reportes.

5. Carga en la Base de Datos RDS (Destino de Datos)

La base de datos MySQL en Amazon RDS es el destino final de los datos procesados. Al usar una base de datos gestionada, se garantiza alta disponibilidad, recuperaci√≥n ante fallos y escalabilidad. Adem√°s, se pueden optimizar las consultas mediante √≠ndices y particiones para mejorar el rendimiento de lectura y escritura.

6. Manejo de Errores y Monitoreo

Implementa un sistema de logging robusto en cada funci√≥n Lambda para capturar detalles de errores y procesos. Puedes integrar AWS CloudWatch Logs para monitorear las funciones y recibir alertas en caso de fallos. Esto facilita la detecci√≥n y soluci√≥n de problemas, asegurando la continuidad del pipeline.

7. Escalabilidad y Flexibilidad

La arquitectura basada en funciones Lambda permite que el pipeline sea altamente escalable. Se pueden agregar nuevas funciones Lambda para manejar diferentes tipos de datos o tablas en la base de datos sin modificar la estructura principal del pipeline. Adem√°s, al trabajar con funciones sin servidor, la soluci√≥n se escala autom√°ticamente seg√∫n la carga, lo que garantiza un uso eficiente de recursos y costos.

8. Optimizaci√≥n de Costos

Monitorea el uso de Lambda, S3 y RDS para mantener los costos bajo control. Considera la posibilidad de programar las funciones Lambda para ejecutarse con memoria y tiempo de ejecuci√≥n optimizados y revisar las m√©tricas de rendimiento de RDS para ajustar el tama√±o de la instancia y las configuraciones de almacenamiento.

- **Demostracion carga incremental :**
  [Video demostracion]()

## **Diagrama E-R**

![Diagrama ER detallado]()

<!-- metodolog√≠a section -->
## **üîß Metodolog√≠a del Trabajo**

Para este proyecto, se implementar√° la metodolog√≠a Scrum, la cual divide el trabajo en partes peque√±as y manejables llamadas "sprints". Cada sprint tiene una duraci√≥n de dos semana, durante las cuales el equipo se enfocar√° en completar un conjunto espec√≠fico de tareas. Al final de cada sprint, se llevar√° a cabo una reuni√≥n de revisi√≥n de sprint (sprint review meeting) donde se realizar√° una demostraci√≥n de los entregables desarrollados, con el objetivo de recibir retroalimentaci√≥n y ajustar la planificaci√≥n para el siguiente sprint seg√∫n lo aprendido. Adem√°s, se llevar√°n a cabo reuniones de seguimiento (Daily Standup) para discutir el progreso y abordar posibles inconvenientes. Este enfoque permite una adaptaci√≥n continua a medida que el equipo avanza.
Detalles de los Sprints:
**Sprint 1 - Comprensi√≥n del Negocio y de los Datos:**
Duraci√≥n: 2 semanas.
Objetivo: Comprender en profundidad el negocio y los datos involucrados en el proyecto.
Actividades:
* Revisi√≥n y an√°lisis detallado de los requisitos del cliente.
* Investigaci√≥n sobre las plataformas de rese√±as como Google Maps y Yelp.
* Identificaci√≥n de posibles fuentes de datos y su relevancia para el proyecto.
Establecimiento de objetivos claros para el proyecto y definici√≥n de las m√©tricas de √©xito.
**Sprint 2 - Preparaci√≥n de los Datos y Modelado:**
Duraci√≥n: 2 semanas.
Objetivo: Preparar los datos y realizar el modelado necesario para el desarrollo del sistema de recomendaci√≥n.
Actividades:
* Extracci√≥n de datos de las fuentes identificadas.
* Limpieza y preparaci√≥n de los datos para su posterior an√°lisis.
* Aplicaci√≥n de t√©cnicas de modelado de datos para generar insights preliminares.
* Identificaci√≥n de posibles problemas o desaf√≠os en los datos y su resoluci√≥n.



## Conclusi√≥n
En esta primera etapa del trabajo consisti√≥ en analizar profundamente la informaci√≥n proporcionada para generar una fuente de datos para las etapas posteriores, sin perder la noci√≥n de que tambi√©n se deb√≠a buscar insights que puedan cambiar desviar el proyecto del objetivo propuesto, lo que resulto en una constante reforma y replanteos tratando siempre de encontrar la coherencia de los datos con el proyecto. La meta final siempre fue buscar una satisfacci√≥n completa del cliente junto con conformaci√≥n de un equipo totalmente acoplado en cuanto a roles adoptados por sus integrantes






